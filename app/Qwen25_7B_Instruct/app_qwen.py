# -*- coding: utf-8 -*-

# ***************************************************
# * File        : app_qwen.py
# * Author      : Zhefeng Wang
# * Email       : wangzhefengr@163.com
# * Date        : 2024-11-11
# * Version     : 0.1.111120
# * Description : description
# * Link        : link
# * Requirement : ç›¸å…³æ¨¡å—ç‰ˆæœ¬éœ€æ±‚(ä¾‹å¦‚: numpy >= 2.1.0)
# ***************************************************

# python libraries
import os
import sys
ROOT = os.getcwd()
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))
import json
import time

from dotenv import find_dotenv, load_dotenv
import streamlit as st
from openai import OpenAI

# global variable
LOGGING_LABEL = __file__.split('/')[-1][:-3]
_ = load_dotenv(find_dotenv())
# x.ai api key
XAI_API_KEY = os.getenv("XAI_API_KEY")


# openai client
client = OpenAI(
    api_key = XAI_API_KEY,
    base_url = "https://api.x.ai/v1",
    # base_url = "http://localhost:8000/v1",
)


def make_api_call(messages, max_tokens, is_final_answer = False):
    """
    æ¨¡å‹è°ƒç”¨

    Args:
        messages (_type_): _description_
        max_tokens (_type_): _description_
        is_final_answer (bool, optional): _description_. Defaults to False.

    Returns:
        _type_: _description_
    """
    # ä¸‰æ¬¡å°è¯•æœºä¼š
    for attempt in range(3):
        try:
            # LLM ç”Ÿæˆå†…å®¹
            response = client.chat.completions.create(
                model = "Qwen2.5-7B-Instruct",
                messages = messages,
                max_tokens = max_tokens,
                temperature = 0.2,
                response_format = {"type": "json_object"},
            )
            content = response.choices[0].message.content
            print(f"Raw API response: {content}")
            # ç»“æœå†…å®¹è§£æ
            try:
                return json.load(content)
            except json.JSONDecodeError as json_error:
                print(f"JSON è§£æé”™è¯¯: {json_error}")
                return {
                    "title": "API Response",
                    "content": content,
                    "next_action": "final_answer" if is_final_answer else "continue"
                }
        except Exception as e:
            if attempt == 2:
                return {
                    "title": "Error",
                    "content": f"Faild after 3 attempts. Error: {str(e)}",
                    "next_action": "final_answer",
                }
            # é‡è¯•å‰ç­‰å¾… 1s
            time.sleep(1)


def generate_response(prompt):
    """
    ç”Ÿæˆæ¨ç†å†…å®¹
    """
    # messages: prompt template
    messages = [
        {
            "role": "system", "content": """
            ä½ æ˜¯ä¸€ä½å…·æœ‰é«˜çº§æ¨ç†èƒ½åŠ›çš„ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æä¾›è¯¦ç»†çš„ã€é€æ­¥çš„æ€ç»´è¿‡ç¨‹è§£é‡Šã€‚å¯¹äºæ¯ä¸€æ­¥ï¼š
            1. æä¾›ä¸€ä¸ªæ¸…æ™°ã€ç®€æ´çš„æ ‡é¢˜ï¼Œæè¿°å½“å‰çš„æ¨ç†é˜¶æ®µã€‚
            2. åœ¨å†…å®¹éƒ¨åˆ†è¯¦ç»†é˜è¿°ä½ çš„æ€ç»´è¿‡ç¨‹ã€‚
            3. å†³å®šæ˜¯ç»§ç»­æ¨ç†è¿˜æ˜¯æä¾›æœ€ç»ˆç­”æ¡ˆã€‚

            è¾“å‡ºæ ¼å¼è¯´æ˜ï¼š
            è¾“å‡ºè¯·ä¸¥æ ¼éµå¾ª JSON æ ¼å¼, åŒ…å«ä»¥ä¸‹é”®ï¼š'title'ï¼Œ'content'ï¼Œ'next_action'(å€¼åªèƒ½ä¸º 'continue' æˆ– 'final_answer' äºŒè€…ä¹‹ä¸€)ã€‚

            å…³é”®æŒ‡ç¤º:
            - è‡³å°‘ä½¿ç”¨ 5 ä¸ªä¸åŒçš„æ¨ç†æ­¥éª¤ã€‚
            - æ‰¿è®¤ä½ ä½œä¸º AI çš„å±€é™æ€§ï¼Œæ˜ç¡®è¯´æ˜ä½ èƒ½åšä»€ä¹ˆå’Œä¸èƒ½åšä»€ä¹ˆã€‚
            - ä¸»åŠ¨æ¢ç´¢å’Œè¯„ä¼°æ›¿ä»£ç­”æ¡ˆæˆ–æ–¹æ³•ã€‚
            - æ‰¹åˆ¤æ€§åœ°è¯„ä¼°ä½ è‡ªå·±çš„æ¨ç†ï¼›è¯†åˆ«æ½œåœ¨çš„ç¼ºé™·æˆ–åè§ã€‚
            - å½“é‡æ–°å®¡è§†æ—¶ï¼Œé‡‡ç”¨æ ¹æœ¬ä¸åŒçš„æ–¹æ³•æˆ–è§†è§’ã€‚
            - è‡³å°‘ä½¿ç”¨ 3 ç§ä¸åŒçš„æ–¹æ³•æ¥å¾—å‡ºæˆ–éªŒè¯ä½ çš„ç­”æ¡ˆã€‚
            - åœ¨ä½ çš„æ¨ç†ä¸­èå…¥ç›¸å…³çš„é¢†åŸŸçŸ¥è¯†å’Œæœ€ä½³å®è·µã€‚
            - åœ¨é€‚ç”¨çš„æƒ…å†µä¸‹ï¼Œé‡åŒ–æ¯ä¸ªæ­¥éª¤å’Œæœ€ç»ˆç»“è®ºçš„ç¡®å®šæ€§æ°´å¹³ã€‚
            - è€ƒè™‘ä½ æ¨ç†ä¸­å¯èƒ½å­˜åœ¨çš„è¾¹ç¼˜æƒ…å†µæˆ–ä¾‹å¤–ã€‚
            - ä¸ºæ’é™¤æ›¿ä»£å‡è®¾æä¾›æ¸…æ™°çš„ç†ç”±ã€‚

            ç¤ºä¾‹ JSON è¾“å‡ºï¼š
            {
                "title": "åˆæ­¥é—®é¢˜åˆ†æ",
                "content": "ä¸ºäº†æœ‰æ•ˆåœ°è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘é¦–å…ˆä¼šå°†ç»™å®šçš„ä¿¡æ¯åˆ†è§£ä¸ºå…³é”®ç»„æˆéƒ¨åˆ†ã€‚è¿™æ¶‰åŠåˆ°è¯†åˆ«...[è¯¦ç»†è§£é‡Š]...é€šè¿‡è¿™æ ·æ„å»ºé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ç³»ç»Ÿåœ°è§£å†³æ¯ä¸ªæ–¹é¢ã€‚",
                "next_action": "continue"
            }

            è®°ä½ï¼šå…¨é¢æ€§å’Œæ¸…æ™°åº¦è‡³å…³é‡è¦ã€‚æ¯ä¸€æ­¥éƒ½åº”è¯¥ä¸ºæœ€ç»ˆè§£å†³æ–¹æ¡ˆæä¾›æœ‰æ„ä¹‰çš„è¿›å±•ã€‚
            å†æ¬¡æé†’ï¼šè¾“å‡ºè¯·åŠ¡å¿…ä¸¥æ ¼éµå¾ª JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹é”®ï¼š'title'ï¼Œ'content'ï¼Œ'next_action'(å€¼åªèƒ½ä¸º 'continue' æˆ– 'final_answer' äºŒè€…ä¹‹ä¸€)ã€‚
            """
        },
        {"role": "user", "content": prompt},
        {"role": "assistant", "content": "ç°åœ¨æˆ‘å°†ä¸€æ­¥æ­¥æ€è€ƒï¼Œä»åˆ†æé—®é¢˜å¼€å§‹å¹¶å°†é—®é¢˜åˆ†è§£ã€‚"}
    ]
    # ------------------------------
    # æ¨ç†è¿‡ç¨‹
    # ------------------------------
    # è®°å½•æ¯æ¬¡æ¨ç†ä¿¡æ¯
    steps = []
    # æ¨ç†æ¬¡æ•°
    step_count = 1
    # æ¨ç†æ€»æ€è€ƒæ—¶é—´
    total_thinking_time = 0
    while True:
        # æ¨¡å‹è°ƒç”¨ï¼Œç”Ÿæˆå†…å®¹
        start_time = time.time()
        step_data = make_api_call(messages = messages, max_tokens = 1000)
        end_time = time.time()
        thinking_time = end_time - start_time
        total_thinking_time += thinking_time
        # ç”Ÿæˆç»“æœè§£æ
        title = step_data.get('title', f'Step {step_count}')
        content = step_data.get('content', 'No content provided')
        next_action = step_data.get('next_action', 'continue')
        # è®°å½•æ¯æ¬¡æ¨ç†ä¿¡æ¯
        steps.append((f"Step {step_count}: {title}", content, thinking_time))
        # æ›´æ–° messages
        messages.append({"role": "assistant", "content": json.dumps(step_data)}) 
        # æœ€å¤š 25 æ­¥ï¼Œä»¥é˜²æ­¢æ— é™çš„æ€è€ƒï¼Œå¯ä»¥é€‚å½“è°ƒæ•´ã€‚
        if next_action == 'final_answer' or step_count > 25: 
            break
        # æ›´æ–°è¿­ä»£æ¬¡æ•°
        step_count += 1
        # åœ¨ç»“æŸæ—¶ç”Ÿæˆæ€»æ—¶é—´
        yield steps, None
    # ------------------------------
    # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    # ------------------------------
    # messages: prompt template
    messages.append({"role": "user", "content": "è¯·æ ¹æ®ä½ ä¸Šé¢çš„æ¨ç†æä¾›æœ€ç»ˆç­”æ¡ˆã€‚"})
    # æ¨¡å‹è°ƒç”¨ï¼Œç”Ÿæˆå†…å®¹
    start_time = time.time()
    final_data = make_api_call(messages = messages, max_tokens = 1000, is_final_answer = True)
    end_time = time.time()
    thinking_time = end_time - start_time
    total_thinking_time += thinking_time
    # ç”Ÿæˆç»“æœè§£æ
    final_content = final_data.get('content', 'æ²¡æœ‰æ¨ç†å‡ºæœ€ç»ˆç»“æœ')
    steps.append(("æœ€ç»ˆæ¨ç†ç»“æœ", final_content, thinking_time))

    yield steps, total_thinking_time




# æµ‹è¯•ä»£ç  main å‡½æ•°
def main():
    st.set_page_config(
        page_title = "Qwen2.5 o1-like Reasoning Chain", 
        page_icon = "ğŸ’¬",
        layout = "wide",
    )
    st.title("Qwen2.5 å®ç°ç±»ä¼¼ o1 model çš„æ¨ç†é“¾")
    st.caption("ğŸš€ A streamlit implementation")
    st.markdown("é€šè¿‡ vLLM éƒ¨ç½²è°ƒç”¨ Qwen2.5-7B-Instruct å¹¶å®ç°ç±»ä¼¼ OpenAI o1 model çš„é•¿æ¨ç†é“¾æ•ˆæœä»¥æé«˜å¯¹å¤æ‚é—®é¢˜çš„æ¨ç†å‡†ç¡®æ€§ã€‚")
    # ç”¨æˆ·è¾“å…¥æŸ¥è¯¢
    user_query = st.text_input("è¾“å…¥é—®é¢˜ï¼š", placeholder = "ç¤ºä¾‹ï¼šstrawberry ä¸­æœ‰å¤šå°‘ä¸ªå­—æ¯ rï¼Ÿ")
    if user_query:
        st.write("æ­£åœ¨ç”Ÿæˆæ¨ç†é“¾ä¸­...")
        # åˆ›å»ºç©ºå…ƒç´ ä»¥ä¿å­˜ç”Ÿæˆçš„æ–‡æœ¬å’Œæ€»æ—¶é—´
        response_container = st.empty()
        time_container = st.empty()
        # ç”Ÿæˆå¹¶æ˜¾ç¤ºå“åº”
        for steps, total_thinking_time in generate_response(user_query):
            with response_container.container():
                for i, (title, content, thinking_time) in enumerate(steps):
                    if title.startswith("æœ€ç»ˆæ¨ç†ç»“æœ"):
                        st.markdown(f"### {title}")
                        st.markdown(content.replace("\n", "<br>"), unsafe_allow_html = True)
                    else:
                        with st.expander(title, expanded = True):
                            st.markdown(content.replace("\n", "<br>"), unsafe_allow_html = True)
            # ä»…åœ¨ç»“æŸæ—¶æ˜¾ç¤ºæ€»æ—¶é—´
            if total_thinking_time is not None:
                time_container.markdown(f"**æ€»æ¨ç†æ—¶é—´ï¼š{total_thinking_time:.2f} ç§’**")

if __name__ == "__main__":
    main()
